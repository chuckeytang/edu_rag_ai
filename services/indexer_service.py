import asyncio
import time
import json
import logging
import os
from typing import Any, Dict, List, Optional

from core.config import settings
from core.rag_config import RagConfig
from services.abstract_kb_service import AbstractKnowledgeBaseService

logger = logging.getLogger(__name__)

# ä¸å†éœ€è¦æœ¬åœ°ç´¢å¼•è·¯å¾„ï¼Œä½†ä¸ºäº†ä¿ç•™å…¼å®¹æ€§ï¼Œå¯ä»¥æš‚æ—¶ä¿ç•™
PERSIST_DIR = settings.INDEX_PATH

class IndexerService:
    def __init__(self, 
                 kb_service: AbstractKnowledgeBaseService): 
        
        self.indices: Dict[str, Any] = {} 
        # ä½¿ç”¨é€šç”¨åç§° self.kb_service
        self.kb_service = kb_service 

        logger.info("IndexerService initialized with Volcano Engine RAG service.")

    async def add_documents_to_index(self, 
                               documents: List[Dict[str, Any]], 
                               knowledge_base_id: str) -> Dict[str, Any]:
        """å‘çŸ¥è¯†åº“ä¸­æ·»åŠ æ–‡æ¡£ã€‚"""
        if not documents:
            logger.warning("No documents provided for indexing. Skipping.")
            return {"status": "success", "message": "No documents to add."}

        document_to_add = documents[0]
        url = document_to_add.get("url")
        text_content = document_to_add.get("text_content")

        doc_name = document_to_add.get("doc_name")
        doc_id = document_to_add.get("doc_id")
        doc_type = document_to_add.get("doc_type")
        meta = document_to_add.get("meta")
        
        if not url and not text_content:
            logger.error("Document dictionary is missing 'url'. Cannot index.")
            return {"status": "error", "message": "Document dictionary is missing 'url'"}
        
        indexing_metadata = {
            "url_present": bool(url), "text_content_present": bool(text_content), 
            "doc_id": doc_id, "doc_name": doc_name, "doc_type": doc_type, 
            "knowledge_base_id": knowledge_base_id, "meta": meta
        }
        logger.info(f"Preparing to index document with the following metadata: {indexing_metadata}")
        
        try:
            result = None
            if url:
                # --- è·¯å¾„ 1: URL å¯¼å…¥ (PDF/DOCX ç­‰) ---
                logger.info(f"Using URL import path for document: {doc_name}")
                result = await self.kb_service.import_document_url(
                    url=url, 
                    doc_id=doc_id, 
                    doc_name=doc_name, 
                    doc_type=doc_type,
                    knowledge_base_id=knowledge_base_id, 
                    meta=meta
                )
            elif text_content:
                # --- è·¯å¾„ 2: TEXT å¯¼å…¥ (PaperCut) ---
                logger.info(f"Using TEXT content import path for document: {doc_name}")
                # ğŸ“¢ è°ƒç”¨æŠ½è±¡æ¥å£çš„æ–°æ–¹æ³•
                result = await self.kb_service.import_document_text( 
                    text_content=text_content, # ä¼ å…¥æ–‡æœ¬å†…å®¹
                    doc_id=doc_id, 
                    doc_name=doc_name, 
                    doc_type=doc_type,
                    knowledge_base_id=knowledge_base_id, 
                    meta=meta
                )
            else:
                raise ValueError("Document dictionary is missing both 'url' and 'text_content'. Cannot index.")

            logger.info(f"Document '{doc_name}' uploaded successfully. Response: {result}")
            # æ³¨æ„ï¼šç™¾ç‚¼è¿”å›çš„æ˜¯ file_idï¼Œæˆ‘ä»¬ç»Ÿä¸€ä½¿ç”¨ kb_doc_id
            return {"status": "success", "result": result, "kb_doc_id": result.get('kb_doc_id')} 
            
        except Exception as e:
            logger.error(f"Failed to upload document '{doc_name}' from URL: {e}", exc_info=True)
            return {"status": "error", "message": str(e), "doc_name": doc_name}

    def delete_nodes_by_metadata(self, knowledge_base_id: str, filters: dict) -> dict:
        """æ ¹æ®å…ƒæ•°æ®è¿‡æ»¤å™¨åˆ é™¤æ–‡æ¡£ã€‚"""
        
        logger.info(f"Attempting to delete documents from '{knowledge_base_id}' with filters: {filters}")
        
        doc_id_to_delete = filters.get("kb_doc_id") 
        if not doc_id_to_delete:
            message = "Deletion requires a 'kb_doc_id' filter (should be FileId)."
            logger.error(message)
            return {"status": "error", "message": message}
            
        try:
            # è°ƒç”¨æŠ½è±¡æ¥å£
            response = self.kb_service.delete_document(
                knowledge_base_id=knowledge_base_id,
                doc_id=doc_id_to_delete
            )
            message = f"Successfully submitted deletion for file '{doc_id_to_delete}'. Response: {response}"
            logger.info(message)
            return {"status": "success", "message": message, "response": response}
            
        except Exception as e:
            message = f"An error occurred during deletion: {e}"
            logger.error(message, exc_info=True)
            return {"status": "error", "message": message}
             
    def update_existing_nodes_metadata(self, knowledge_base_id: str, doc_id: str, metadata_update_payload: dict) -> dict:
        """æ›´æ–°ç°æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®ã€‚æ­¤æ–¹æ³•ä»…ä½œä¸ºè­¦å‘Š/è½¬å‘ã€‚"""
        # æ³¨æ„ï¼šè¿™é‡Œç§»é™¤äº†ç¡¬ç¼–ç çš„ knowledge_base_id
        
        logger.info(f"Performing metadata update for doc_id: {doc_id} in KB '{knowledge_base_id}' with payload: {metadata_update_payload}")
        
        if not doc_id or not metadata_update_payload:
            message = "Update requires a 'doc_id' and metadata payload."
            logger.warning(message)
            return {"status": "error", "message": message}
            
        try:
            # æ­¤å¤„è°ƒç”¨ update_document_metaï¼Œç”±åº•å±‚æœåŠ¡å†³å®šæ˜¯å¦æ”¯æŒ
            response = asyncio.run(self.kb_service.update_document_meta(
                knowledge_base_id=knowledge_base_id,
                doc_id=doc_id,
                meta_updates=[metadata_update_payload] 
            ))
            
            # ç”±äºæ­¤æ–¹æ³•æ˜¯åŒæ­¥çš„ï¼Œéœ€è¦ä½¿ç”¨ asyncio.run åŒ…è£…å¼‚æ­¥è°ƒç”¨ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ­¤æ–¹æ³•ä¹Ÿåº”è¯¥æ”¹ä¸ºå¼‚æ­¥
            return response
            
        except Exception as e:
            message = f"An error occurred during metadata update: {e}"
            logger.error(message, exc_info=True)
            return {"status": "error", "message": message}
           
    async def update_document_meta(self, 
                             doc_id: str, 
                             file_key: str,
                             knowledge_base_id: str, 
                             meta_updates: List[Dict[str, Any]]) -> dict:
        """é€šç”¨å…ƒæ•°æ®æ›´æ–°æ–¹æ³•ï¼Œç›´æ¥è°ƒç”¨ AbstractKnowledgeBaseServiceã€‚"""
        try:
            logger.info(f"Preparing to update meta for doc {doc_id} in KB {knowledge_base_id}. Meta Updates: {meta_updates}")
            
            # è°ƒç”¨æŠ½è±¡æ¥å£
            response = await self.kb_service.update_document_meta(
                knowledge_base_id=knowledge_base_id,
                file_key=file_key,
                doc_id=doc_id,
                meta_updates=meta_updates
            )
            
            if response.get("status") == "not_implemented":
                return response
            
            return {
                "message": f"Successfully updated meta for doc {doc_id}.",
                "status": "success",
                "doc_id": doc_id
            }
                
        except Exception as e:
            logger.error(f"Failed to update document meta for doc {doc_id}: {e}", exc_info=True)
            return {
                "message": f"An API error occurred: {str(e)}",
                "status": "error",
            }
